{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1YmPgUQPOg_HiKmfQGmMcR8q6l0ijbrhs","authorship_tag":"ABX9TyMzcuIi1GUz/NOkKslPfNHQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oXb4AmrFfA74","executionInfo":{"status":"ok","timestamp":1681834686921,"user_tz":240,"elapsed":8369,"user":{"displayName":"KALLEM MANIKUMAR REDDY","userId":"01812327029293110733"}},"outputId":"1c41edc8-a34e-417f-a594-658b0877c1c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/CPDP_GroupProject"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKCj8yeFfMpl","executionInfo":{"status":"ok","timestamp":1681834689293,"user_tz":240,"elapsed":196,"user":{"displayName":"KALLEM MANIKUMAR REDDY","userId":"01812327029293110733"}},"outputId":"c2ac198a-d433-43af-eb54-987da0fa1cb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CPDP_GroupProject\n"]}]},{"cell_type":"code","source":["ls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3UJq6T7fPYH","executionInfo":{"status":"ok","timestamp":1681834690770,"user_tz":240,"elapsed":171,"user":{"displayName":"KALLEM MANIKUMAR REDDY","userId":"01812327029293110733"}},"outputId":"9a373485-2a29-4ee3-e39b-6129490987ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["' FeatureVectors.ipynb'   ImageSearch.ipynb              \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n"," FeatureVectors.py       ' ImageSearch_Parallel.ipynb'   QuerySearch.ipynb\n"," \u001b[01;34mImage_Database\u001b[0m/          ImageSearch_parallel.py        QuerySearch.py\n"," \u001b[01;34mImage_Filters\u001b[0m/           ImageSearch_Serial.ipynb\n"," \u001b[01;34mImage_Histograms\u001b[0m/        ImageSearch_Serial.py\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Image-Search-using-Parallel-Computing-master')\n","sys.path.append('/content/drive/MyDrive/CPDP_GroupProject/Image_Histograms/')\n","sys.path.append('/content/drive/MyDrive/CPDP_GroupProject/ConvolutionalFilters /')\n"],"metadata":{"id":"tTFsHFNlfSFP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NMR2TYt_qMay"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from Image_Filters import NoiseReduction, ConvolutionalFilters\n","\n","class FeatureVectors:\n","    \"\"\"Extracts various feature vectors from image \"\"\"\n","\n","    def __init__(self, image):\n","        noise_reducer = NoiseReduction(image)\n","        self.image = noise_reducer.applyGaussianBlur()\n","\n"]},{"cell_type":"code","source":["def __getMeanIntensity(self):\n","    # Returns the mean intensity of image\n","\n","    return [round(np.average(self.image[:, :, channel]), 5) for channel in range(3)]\n","\n","\n","    "],"metadata":{"id":"ZlMxFydftao_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def __getStdIntensity(self):\n","    # Returns the standard deviation of intensity of image\n","    \n","    stdIntensity = [round(np.std(self.image[:, :, channel]), 5) for channel in range(3)]\n","    \n","    return stdIntensity\n","\n","    "],"metadata":{"id":"Fde5YHActjHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_rgb_histogram_vector(self):\n","    # Returns the 3D (RGB) histogram vector of the image\n","\n","    bins = 12\n","    ranges = [0, 256]\n","    channel_ranges = [ranges, ranges, ranges]\n","\n","    histogram_3d = cv2.calcHist([self.image], [0, 1, 2], None, channel_ranges, [bins]*3)\n","    rgb_histogram = list(histogram_3d.ravel())\n","\n","    return rgb_histogram\n","\n","    "],"metadata":{"id":"fyWi46-Stguk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_hu_moments(image):\n","    # Returns Hu-Moments vector of image\n","\n","    edge_filter = ConvolutionFilter(image)\n","    canny_edges = edge_filter.apply_canny_edge()\n","    hu_moments = cv2.HuMoments(cv2.moments(canny_edges)).flatten()\n","    return list(hu_moments.ravel())\n"],"metadata":{"id":"QVSM4iRHtmOC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getFeatureVector(self):\n","    \"\"\"Return a Python list of complete feature vectors.\n","    \n","    Extracts statistics, 3-D histogram, and Hu moments from image and \n","    appends into a single list.\n","    \"\"\"\n","    meanIntensity = self.__getMeanIntensity()\n","    stdIntensity = self.__getStdIntensity()\n","    rgbHistogram = self.__getRGBHistogramVector()\n","    huVectors = self.__getHuMoments()\n","\n","    # use list comprehension and extend method to create a single feature vector\n","    featureVectors = [x for vector in [meanIntensity, stdIntensity, rgbHistogram] for x in vector]\n","    featureVectors.extend(huVectors)\n","    return featureVectors\n","\n"],"metadata":{"id":"4kXVEivwtntx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YvK691dwtpH3"},"execution_count":null,"outputs":[]}]}